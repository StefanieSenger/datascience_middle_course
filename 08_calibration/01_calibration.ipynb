{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d95bdb5-0815-4d30-8c9f-6aa194bf4355",
   "metadata": {},
   "source": [
    "# Classifier calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b169f8e-7a4b-437c-854c-2a8523eeeb4a",
   "metadata": {},
   "source": [
    "For some applications, experts would like to interpret the output of the probabilities that a classifier is providing. Let's take the example of weather forecasting and specifically prediction of severe rainfall classification. If an event declare a 80% probability to have a severe rainfall, on 100 events with such particular weather, 80 of them had a severe rainfall outcome while 20 of them did not.\n",
    "\n",
    "Thus, it happens that classifiers do not provide a probabilities that translate into such interpretation: these classifiers are not calibrated. When such interpretations are required, one should make sure that classifiers are calibrated and if not, should calibrate them.\n",
    "\n",
    "In this notebook, we will investigate how to check if a classifier or not is calibrated and how to calibrate one.\n",
    "\n",
    "## Presentation of our dataset\n",
    "\n",
    "Let's load the dataset where we will illustrate our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f0573-eb90-4f4f-bfc7-5b900f3978c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10791af-f784-496f-847e-cd9ee0071d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/weather.csv\", parse_dates=[\"Date\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f5372c-e73c-4ac0-a23a-cf739c93d7ca",
   "metadata": {},
   "source": [
    "This dataset contains information about weather forecast. We will modify this dataset such that our target will be the `\"Rainfall\"` column. We will create a classification problem by thresholding the target to get to category: >50 mm that will be severe rainfall and <50 mm that will not be a severe rainfall.\n",
    "\n",
    "In addition, we will drop the `\"RainToday\"` and `\"RainTomorrow\"` features that are the link with the original classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20339b-ecd0-4088-a59a-9468189b00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_name = \"Rainfall\"\n",
    "data = data.dropna(axis=\"index\", subset=[target_name])\n",
    "X = data.drop(columns=[\"RainToday\", \"RainTomorrow\", target_name])\n",
    "y = (data[target_name] > 50).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbecf3b-dce6-4e2a-89cd-3f42f5101e9b",
   "metadata": {},
   "source": [
    "Now let's have a look at the available features and their types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489bd199-ab04-448b-b7fa-0f0e183bf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc40b9d-6444-4669-9438-0368c5a21d6c",
   "metadata": {},
   "source": [
    "So we can see that we will need to:\n",
    "\n",
    "- encode the `\"Date\"` feature;\n",
    "- encode the column the `object` columns using an `OrdinalEncoder`;\n",
    "- let the numerical features as-is;\n",
    "- impute the missing values with a constant.\n",
    "\n",
    "In addition, let's check the distributionof the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bf237-fc4e-44f9-a1d9-e587e1882e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209002a-271a-4c95-b82c-1eea20993f94",
   "metadata": {},
   "source": [
    "Thus, we can observe that the problem is imbalanced.\n",
    "\n",
    "## Our machine learning model\n",
    "\n",
    "We use a `BalancedRandomForestClassifier` on this problem. First, let's start to create a preprocessor.\n",
    "\n",
    "### Date parser\n",
    "\n",
    "Let's create a small function that would encode the date into three different features for the day, month, and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192678c-1a3f-4c7c-a4f8-0226422a8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_parser(X):\n",
    "    X = X.copy()\n",
    "    X[\"day\"] = X[\"Date\"].dt.day\n",
    "    X[\"month\"] = X[\"Date\"].dt.month\n",
    "    X[\"year\"] = X[\"Date\"].dt.year\n",
    "    return X.drop(columns=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05bed1-6a7d-4fd4-845b-794608ff4748",
   "metadata": {},
   "source": [
    "### Data preprocessor\n",
    "\n",
    "Now, let's create a preprocessor to encode the categorical columns and let the numerical columns as-is. We will use `make_column_selector` based on the dtype to select the right columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a1d89-c0db-4eb2-9762-7e9d3dfbf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "numerical_columns = make_column_selector(dtype_exclude=[object, \"datetime\"])(X)\n",
    "categorical_columns = make_column_selector(dtype_include=object)(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0064a-361b-44c6-aa9c-abf12c8405a5",
   "metadata": {},
   "source": [
    "Now, we will use a `ColumnTransformer` to encode and impute the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba89bb-8f03-4a1e-878b-405d812caa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"categorical\",\n",
    "            make_pipeline(\n",
    "                OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "                SimpleImputer(strategy=\"constant\", fill_value=-1),\n",
    "            ),\n",
    "            categorical_columns,\n",
    "        ),\n",
    "        (\n",
    "            \"numerical\",\n",
    "            SimpleImputer(strategy=\"constant\", fill_value=-1),\n",
    "            numerical_columns,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba281549-5415-4fbf-a9df-f44fbdfb9a6b",
   "metadata": {},
   "source": [
    "### Full model\n",
    "\n",
    "Now that we have our preprocessor, we can create our entire model finshing by a `BalancedRandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029539f3-7cdd-442d-ab79-0245b34fae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "model = make_pipeline(\n",
    "    FunctionTransformer(date_parser),\n",
    "    preprocessor,\n",
    "    BalancedRandomForestClassifier(n_jobs=-1, random_state=0),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da26ad-ee72-47d9-ad95-2243e6e24e81",
   "metadata": {},
   "source": [
    "We can now evaluate our model using cross-validation. Since we deal with time series, we will use a `TimeSeriesSplit` cross-validation scheme.\n",
    "\n",
    "In addition, we will use several metrics: balanced accuracy, average precision, and brier loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0281302-283e-41de-9412-cf436ec296a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score, average_precision_score, brier_score_loss\n",
    "\n",
    "scoring = {\n",
    "    \"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "    \"average_precision\": make_scorer(average_precision_score, needs_proba=True),\n",
    "    \"brier_score\": make_scorer(\n",
    "        brier_score_loss, greater_is_better=False, needs_proba=True,\n",
    "    ),\n",
    "}\n",
    "cv = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ddcf7-2e38-4a86-bf73-cbe696eda9c9",
   "metadata": {},
   "source": [
    "We are finally ready to run our cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb91f6-9c00-4402-9d95-e427376be432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa45309-05d8-4b47-afb4-bd300dbcf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb01025-8045-49f9-b1de-5c2e037276d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8dd01-87b6-4f7c-afd1-23da7ed8f32c",
   "metadata": {},
   "source": [
    "### A note about the Brier score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d885a6-7de5-4678-937d-9743d553e759",
   "metadata": {},
   "source": [
    "The Brier score (that is indeed a loss) measures the if the probability predicted by a classifier are accurate. An uncalibrated classifier will result in an higher Brier score than a well calibrated classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909aae35-5d91-4ae0-b73a-38b6e469af15",
   "metadata": {},
   "source": [
    "## About classifier calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca427e-a60a-42f5-af70-f0e3f4be5e36",
   "metadata": {},
   "source": [
    "Now, that we have our model, we will show how to check if it is calibrated. Let's first make a single train-test split and train our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a53e4-b32e-4c67-9534-e11a83090a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.5, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebd2c8-2c81-4c97-8d46-078f17193827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f9679-d5e3-46ec-94ca-45563ec4e94a",
   "metadata": {},
   "source": [
    "We can use the `CalibrationDisplay` that will plot the fraction of positive against the mean predicted probability. For a calibrated classifier, we would expect the fraction of positive to be aligned wiht the mean predicted probability, such that is follow our original explanation. Let's check if our classifier is calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7964d-4df0-4cf7-a509-43f5b2ffe88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1681e4-d047-46ef-8391-df00c7eb0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "display = CalibrationDisplay.from_estimator(\n",
    "    model, X_test, y_test, strategy=\"quantile\", n_bins=20,\n",
    "    name=\"Original classifier\", markersize=10,\n",
    ")\n",
    "display.ax_.legend(loc=\"best\", bbox_to_anchor=(1, 0.5))\n",
    "_ = display.ax_.set_title(\"Reliabiliry of original classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c753b-70b1-43af-adf0-2a63aca55b6a",
   "metadata": {},
   "source": [
    "We observe that our classifier is not well calibrated since it does not follow the diagonal.\n",
    "\n",
    "When a model is not calibrated, it can be either:\n",
    "\n",
    "- overconfident: the predicted probability will be higher than the fraction of positives, or\n",
    "- underconfident: the predicted probability will be lower than the fraction of positives.\n",
    "\n",
    "Here, our model is clearly overconfident. A classifier can be recalibrated using `CalibratedClassifierCV`. This classifier will use a calibrator that will fit a function to map the probabilities of the uncalibrated classifier to the true predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81037813-26a3-4be0-9da7-da2fcdfaab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model_calibrated = CalibratedClassifierCV(\n",
    "    model, method=\"isotonic\",\n",
    ")\n",
    "model_calibrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bce1d-6c47-44a1-9dd4-2c1ff2757b31",
   "metadata": {},
   "source": [
    "Now, we can evaluate our model with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04005e5c-bc6e-45d7-8a32-84ea33e59016",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "    model_calibrated, X, y, cv=cv, scoring=scoring, n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa70fd-9026-48c7-87af-6823c21c6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdba861-04bb-4d43-8caa-b53ed3a120a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea13c6-8464-4141-a0ef-6bfba033793d",
   "metadata": {},
   "source": [
    "We observe that while the balanced accuracy goes down, the average precision remains more or less stable. More importantly the Brier score is much smaller meaning that our classifier is better calibrated. We can check now the reliability diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1e788-5962-40fd-9c4d-6d49eb8dd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_calibrated.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90b6ae-2111-43d5-91a5-9d91c9ff012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = CalibrationDisplay.from_estimator(\n",
    "    model_calibrated, X_test, y_test, strategy=\"quantile\", n_bins=20\n",
    ")\n",
    "display.ax_.legend(loc=\"best\", bbox_to_anchor=(1, 0.5))\n",
    "_ = display.ax_.set_title(\"Reliability of calibrated classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609b2e8-20aa-42a4-8868-fefcfb709690",
   "metadata": {},
   "source": [
    "We observe that our classifier follow the diagonal. Since we are using quantile and most probability are in the lower probability, we don't have data point above 10%. We could force the binning to use a uniform sampling. However, we might have very few points and thus a lot of variance then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7e6f9-9da2-4794-965f-452b2a6d252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = CalibrationDisplay.from_estimator(\n",
    "    model_calibrated, X_test, y_test, strategy=\"uniform\", n_bins=20\n",
    ")\n",
    "display.ax_.legend(loc=\"best\", bbox_to_anchor=(1, 0.5))\n",
    "_ = display.ax_.set_title(\"Reliability of calibrated classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('dev': conda)",
   "language": "python",
   "name": "python396jvsc74a57bd09a169727f211857ff40b7480da7adfec0d4f2de575b69ddb6e8fbd736e9b2f58"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
