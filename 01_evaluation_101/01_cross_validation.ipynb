{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35febf00-3e4a-4eba-bab4-34f45849382e",
   "metadata": {},
   "source": [
    "# Evaluating a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acfec6-db49-4d41-ad41-1f1d1a849942",
   "metadata": {},
   "source": [
    "In this notebook, we intend to:\n",
    "\n",
    "- introduce in an intuitive manner a linear model on a regression task\n",
    "- introduce the user API of scikit-learn\n",
    "- introduce the concept of training and testing error\n",
    "- introduce the concept of cross-validation\n",
    "- compare a model with some other baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8b3ae-4ecf-43af-8af4-bb07c5660c36",
   "metadata": {},
   "source": [
    "# Gentle introduction to linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1f8b4-dc89-4a43-b8cf-0b17cdfc3451",
   "metadata": {},
   "source": [
    "We will start by introducing the concept of linear regression. First, we will not use any advanced tool as scikit-learn and instead made use of only NumPy. First, let's load the dataset that we will use for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/penguins_regression.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efdd5-3e61-4051-bd99-e09a50f9e192",
   "metadata": {},
   "source": [
    "We will use a dataset containing records of some penguins flipper length and body mass. The first task that we want to accomplish is to learn a predictive model where we would like to estimate the body mass of a penguins given its flipper length. Since the target is continuous, this problem is a regression problem.\n",
    "\n",
    "Let's first have a look at the relationship between these measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef773e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff485a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=data.columns[0], y=data.columns[1])\n",
    "_ = ax.set_title(\"Can I predict penguins' body mass?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37a4e2-8b53-4862-ae3a-bafc20695545",
   "metadata": {},
   "source": [
    "We see could see that we have a linear trend between the flipper length and the body mass: longer is the penguin's flipper, heavier is the penguin. The first predictive model that we would like to have will model the relationship between these two variables as a linear relationship.\n",
    "\n",
    "Thus, in this example:\n",
    "\n",
    "- the flipper length is a feature. Here, we will only use a single feature. In practise, we will have many features when trying to create a predictive model.\n",
    "- the body mass is the variable that we would like to predict, thus it is the target.\n",
    "\n",
    "A pair of measurement (flipper length, body mass) is called a sample. We learn a predictive model from available pair of such features/target. At prediction time, we will only have the features available and the goal is to predict the potential target. To evaluate a predictive model, we can then use some of the features and compare the predictions given by the model with the true target.\n",
    "\n",
    "For the rest of this lecture, we will denote the variable `X` as the matrix of shape `(n_samples, n_features)` and the target will be denoted by the variable `y` as a vector of shape `(n_samples,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[[\"Flipper Length (mm)\"]], data[[\"Body Mass (g)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afac66-fa48-4767-9b1f-38fb8600cd81",
   "metadata": {},
   "source": [
    "To start, we would like to model the relationship between `X` and `y` by a linear relationship. Thus, we can formalize it as:\n",
    "\n",
    "$$\n",
    "y = X \\beta\n",
    "$$\n",
    "\n",
    "where $\\beta$ are the coefficients of our linear model. We could expand this equation for all available features as:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412c22a-128c-4a9a-aec2-b8d537714bfd",
   "metadata": {},
   "source": [
    "Here, we only have a single feature, $\\beta_1$, that is the flipper length.\n",
    "\n",
    "Finding a linear model is equivalent to find the \"best possible\" $\\beta$. What is the best $\\beta$? The best $\\beta$ would be the $\\beta$ that once used with $X$ will predict $\\hat{y}$ such that the $\\hat{y}$ (i.e. the predicted target) is as closed as possible of $y$ (i.e. the true target). Thus, we would like to minimize an error. We can find the $\\beta$ from the equation above:\n",
    "\n",
    "$$\n",
    "X^T y = X^T X \\beta\n",
    "$$\n",
    "\n",
    "and thus\n",
    "\n",
    "$$\n",
    "\\beta = (X^T X)^{-1} X^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78f044-5443-4a9b-956c-c1f640825225",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Using NumPy, find $\\beta$ ($\\beta_0$ and $\\beta_1$) using the normal equation above.</li>\n",
    "        <li>Once you found these $\\beta$ compute the predictions given the matrix $X$.</li>\n",
    "        <li>Plot the true data ($X$) and target ($y$) as previously done. Plot the predicted target given by the model ($\\hat{y}$).</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43718253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fda88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ec042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_04.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e454624-b0bd-4447-8574-f951dc4f444b",
   "metadata": {},
   "source": [
    "## Introduction to scikit-learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e718a540-c7ef-48e4-952e-acdea9ecb874",
   "metadata": {},
   "source": [
    "Scikit-learn is using Python classes to give some state to Python object. In machine-lerning context, it is handy to have object that will \"learn\" some internal states. Once these states are learnt, the object could be used to make the prediction. In scikit-learn, we thus have Python class to create instance that will have:\n",
    "\n",
    "- a `fit` method to learn the internal states\n",
    "- a `predict` method to output some predicted values given some input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683d587-b661-4e9b-913c-b67da2a8c829",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    Given the linear model used in the previous section. Create a Python class with:\n",
    "    <ul>\n",
    "        <li>a <tt>fit</tt> method where you will compute the $\\beta$.</li>\n",
    "        <li>a <tt>predict</tt> method that will output the predictions given <tt>X</tt> as input.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35352890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_05.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_06.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_07.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb598bb5-52c5-4a8f-8019-983a9ca9b093",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    Now, use scikit-learn to create a <tt>LinearRegression</tt> model to repeat the previous experience. Such model will be available in the module <tt>sklearn.linear_model</tt>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_09.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d84c07-0bba-4024-a567-0a88dd1ff73d",
   "metadata": {},
   "source": [
    "A scikit-learn predictive model will store the state of the model with attribute that finishes with an underscore. They are fitted attributes. For our linear model, they will be `coef_` and `intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317c519-3067-4209-a514-b758abd44c63",
   "metadata": {},
   "source": [
    "## Properly evaluate a model via cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5131b76b-d4cd-437e-a16e-86ff50d5e4a1",
   "metadata": {},
   "source": [
    "As previously stated, we can compute a metric to evaluate how good our trained model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37441667-d63d-4e2a-aaae-0114fa01bb96",
   "metadata": {},
   "source": [
    "However, there is something wrong in what we just did. Indeed, if we would have a predictive model that would have memorize the training set, we would have obtain a perfect score. In practice, we don't use the same dataset to train and test a model to get a true estimate of the capability of a model to predict targets on new dataset. A metric computed on the training set is also called empirical error while the error computed on the testing set is called generalization error.\n",
    "\n",
    "Thus, we could have first split our dataset into two sets: a training set to train our model and a testing set to check the statistical performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fabd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1ff9e-afd9-464f-9bdf-8ebeb922c44e",
   "metadata": {},
   "source": [
    "We observe that our model is not as precise on the testing set than on the training set. But this is not castastophic. We can show with another type of a model (decision tree) that the different can be quite drastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e885e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483aa004",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7be1aa-a040-4e2d-80d5-c01b6170878a",
   "metadata": {},
   "source": [
    "Let's come back to our linear model trained and tested on distinct sets. We observe a small difference between the training and testing scores. However, we are unable to know if the difference is significant, meaning that the difference might only be due to some random fluctuation given by our random initial data split. A proper evaluation should provide an estimate of the distribution of the different scores and not only a point-estimate. Cross-validation is a framework that would allow to take into account such variation.\n",
    "\n",
    "The idea between cross-validation is to repeat the evaluation by varying the train and test set. This evaluation will therefore take into account the fluctuation that could happen in the \"fit\" process as well as in the \"predict\" process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cfc30f-e857-4060-ae55-093b040a8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ac8b6-af9b-49c8-a486-0f7bf8a5f748",
   "metadata": {},
   "source": [
    "Scikit-learn provides the `sklearn.model_selection.cross_validate` function to repeat this train-test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c222b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cv_results = cross_validate(\n",
    "    model, X, y, cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a79921",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac34679",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a56ff9-58df-4f74-a08b-21aef30c31aa",
   "metadata": {},
   "source": [
    "We can observe that we have close result between the train and test score. However, the distribution of the test score is a bit larger. We could indeed use a repeated k-fold cross-validation to get more estimate and plot the distributions of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18468d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "cv = RepeatedKFold(n_repeats=10, n_splits=3, random_state=0)\n",
    "cv_results = cross_validate(\n",
    "    model, X, y, cv=cv,\n",
    "    scoring=\"r2\",\n",
    "    return_train_score=True\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cv_results[[\"train_score\", \"test_score\"]].plot.hist(alpha=0.7)\n",
    "ax.set_xlim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1086fa24-d70b-4d3c-a9f4-246b694ecf5a",
   "metadata": {},
   "source": [
    "Visually, we can see that our model is behaving similarly on the training and testing sets with quite a small variation. This is quite a good new. Indeed, we can trust these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfeaf3f-bf06-4f8e-8b6e-31e835279278",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <p>Repeat the cross-validation using a <tt>KFold</tt> strategy. However, explicitely set the parameter <tt>shuffle=False</tt>. Explain the differences that you observe compared to our previous analysis.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c9678-43ba-4c22-a5e6-8462ef07fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccbb03-920f-448d-98d9-9b14086cc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_11.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db7b81-a170-4e89-ad2c-080e9be77cdd",
   "metadata": {},
   "source": [
    "## Use baseline during evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a8dc06-fabb-463c-8bf1-f79f46259c4e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <p>You will use some baseline model to compare your previous linear model. For the cross-validation, get at least 30 estimates of the scores.</p>\n",
    "    <ul>\n",
    "        <li>Use a <tt>sklearn.dummy.DummyRegressor</tt> that will predict the mean target of the training set.</li>\n",
    "        <li>Use the function <tt>sklearn.model_selection.permutation_test_score</tt> to get an estimate of the score of a completely random predictive model.</li>\n",
    "        <li>Plot the distributions of the original linear model and the two above baseline. Plot only the test score distribution.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8cfb92-370a-4f3e-b497-c042326e52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_repeats=10, n_splits=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e45ec76-f499-48fc-905a-61ef03ae5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_12.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_13.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_14.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_15.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9909cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_16.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c931e3-d4ce-4a61-bce0-38042d32975c",
   "metadata": {},
   "source": [
    "## Evaluate the uncertainty of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918d06f-d554-4b9d-94eb-0c44a14b872c",
   "metadata": {},
   "source": [
    "As previously stated, cross-validation will evaluate the uncertainty of the full process fit/predict. Thus, it will involve that we are evaluated different models, one model on each different train set of the cross-validation.\n",
    "\n",
    "If we have a single model, one can evaluate the uncertainty by bootstrapping the prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fdf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61a495-f118-44ec-9f38-b40afa480ee5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <p>You will use some baseline model to compare your previous linear model. For the cross-validation, get at least 30 estimates of the scores.</p>\n",
    "    <ul>\n",
    "        <li>Compute the predictions of the model on the testing set.</li>\n",
    "        <li>Create 100 bootstrap samples from the predictions (you can use <tt>np.random.choice</tt>).</li>\n",
    "        <li>Plot the distribution of these bootstrap samples.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_17.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
