{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d417a39f-d85b-4e7a-9dd6-a7788724e693",
   "metadata": {},
   "source": [
    "# Linear models - Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4cbea-d70a-405b-b46e-9003dd188d10",
   "metadata": {},
   "source": [
    "In this notebook, we will have a deeper look to linear models and especially the concept of loss functions. We will reuse the previous regression problem where we wanted to model the relationship between  the penguins' flipper length and their body mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621aae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/penguins_regression.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae274c-a949-43ba-b866-8e756b928954",
   "metadata": {},
   "source": [
    "We observe that there is a reasonable linear relationship between the flipper length and the body mass. Here, our target to be predicted will be the body mass while the flipper length will be a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[[\"Flipper Length (mm)\"]], data[\"Body Mass (g)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43185367-819d-43d2-97fc-2abb0ec1535d",
   "metadata": {},
   "source": [
    "In the previous notebook, we used a <tt>LinearRegression</tt> from scikit-learn and show that we could learn the state of the model from the data when calling <tt>fit</tt> and use these states for prediction when calling the method <tt>predict</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7777961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(X, y_pred, label=model.__class__.__name__, color=\"black\", linewidth=4)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455b2df-9a48-447d-bb0c-4b31db991dbf",
   "metadata": {},
   "source": [
    "In the previous notebook, we quickly mentioned that the linear regression model was minizing an error between the true target and the predicted target. This error is also known as loss function. The loss that is minimized in this case is known as the least squared error. This loss is defined as:\n",
    "\n",
    "$$\n",
    "loss = (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "that is\n",
    "\n",
    "$$\n",
    "loss = (y - X \\beta)^2\n",
    "$$\n",
    "\n",
    "We can check what the loss look likes in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065c411-0c8a-4325-b65e-f02f3b49f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_loss(y_true, y_pred):\n",
    "    loss = (y_true - y_pred) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a75de4-bd03-4920-ba83-3fe75730c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xmin, xmax = -2, 2\n",
    "xx = np.linspace(xmin, xmax, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e7005-de7c-4a32-ad48-ec0f23bd4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(xx, se_loss(0, xx), label=\"SE loss\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18f8b0-156a-4f4f-af48-d48419f4fa45",
   "metadata": {},
   "source": [
    "Looking at the shape of the loss function, we see that the bell shape of the loss will impact greatly the large error.\n",
    "In practice, this will have an impact on the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f9375-cf38-43c3-8484-d418479ca7cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Create a new sample in the dataset that we will call an outlier. This penguin will have a flipper length of 230 mm and a body mass of 300 g.</li>\n",
    "        <li>Plot the new dataset.</li>\n",
    "        <li>Fit a <tt>LinearRegression</tt> model on this new dataset. When calling <tt>fit</tt> pass a <tt>sample_weight</tt> provide 10x more weight to the last sample (outlier) than on other samples.</li>\n",
    "        <li>Plot the predictions given by this model.</li>\n",
    "    </ul>\n",
    "    What is the effect of having an outlier in the dataset?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba83376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_04.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_05.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_06.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f30e43-df61-4553-b62f-bdb17fc6453f",
   "metadata": {},
   "source": [
    "Instead of using the squared loss, we will use a loss known as the Huber loss. In this regard, we will use the `HuberRegressor` model available in scikit-learn. We will fit this model in the exact similar way that we previously did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "model = HuberRegressor()\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(X, y_pred, label=model.__class__.__name__, color=\"black\", linewidth=4)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12888fa-3816-4b2b-946d-75734ce3a9d3",
   "metadata": {},
   "source": [
    "We observe that the outlier has much less weight than in the case of the least squared loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c16f62-a557-417d-80c5-20b511ac9fcd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Look at the documentation of the <tt>HuberRegressor</tt>.</li>\n",
    "        <li>Similarly to the loss function <tt>se_loss</tt>, define a function <tt>huber_loss</tt> to depict the shape of the loss.</li>\n",
    "        <li>Reproduce the same for the absolute loss.</li>\n",
    "    </ul>\n",
    "    Why outliers have less impact on the fit of an Huber regressor than an ordinary least square.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_07.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f82bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_09.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b0f9f-2fe1-4429-8c87-75df8d6aa083",
   "metadata": {},
   "source": [
    "We observe that the Huber and absolute losses are penalizing less outliers. It means that these outliers will be less attractive and we will not try to find $\\beta$ that try to minimize this large error. Indeed, the <tt>HuberRegressor</tt> will give an estimator of the median instead of the mean.\n",
    "\n",
    "If one is interesting in other quantile than the median, scikit-learn provides an estimator called `QuantileRegressor` that minimizes the pinball loss and provide a estimator of the requested quantile. For instance, one could request the median in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f95323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "model = QuantileRegressor(quantile=0.5)\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(X, y_pred, label=model.__class__.__name__, color=\"black\", linewidth=4)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157bff8-ab8f-46c1-b47b-6ade05d28c23",
   "metadata": {},
   "source": [
    "The advantage of this estimator is that one can estimate some confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a524fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantileRegressor(quantile=0.5, solver=\"highs\")\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "y_pred_median = model.predict(X)\n",
    "\n",
    "model.set_params(quantile=0.90)\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "y_pred_90 = model.predict(X)\n",
    "\n",
    "model.set_params(quantile=0.10)\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "y_pred_10 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.plot.scatter(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\n",
    "ax.plot(X, y_pred_median, label=f\"{model.__class__.__name__} - median\", color=\"black\", linewidth=4)\n",
    "ax.plot(X, y_pred_90, label=f\"{model.__class__.__name__} - 90th percentile\", color=\"tab:orange\", linewidth=4)\n",
    "ax.plot(X, y_pred_10, label=f\"{model.__class__.__name__} - 10th percentile\", color=\"tab:green\", linewidth=4)\n",
    "_ = ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d356930-4027-4ef7-be72-5b3af1800893",
   "metadata": {},
   "source": [
    "Here, we provide a 80% confidence interval around the median by fitting the 10th and 90th percentiles of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
