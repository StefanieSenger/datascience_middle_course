{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f31d61-58b8-4d75-8da7-8d580b22c8f7",
   "metadata": {},
   "source": [
    "# Linear models - Beyond linear separations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3d077-8e3e-40f2-9bf9-688ccd797592",
   "metadata": {},
   "source": [
    "In this notebook, we will illustrate that using the right preprocessing, the separation of a linear model can make this model flexible enough to fit data where the link between the features and the target is non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b7234-da6d-4dd0-8a38-cf29114256ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f22db-2017-4ad7-86f7-e27bcee47825",
   "metadata": {},
   "source": [
    "## Limitation of linear separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13585576-f6a0-49d0-92cd-dad833c9e58a",
   "metadata": {},
   "source": [
    "We will create a complex classification toy dataset where we expect a linear model to not work.\n",
    "Let's generate the dataset and make a scatter plot of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b78260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "feature_names = [\"Feature #0\", \"Features #1\"]\n",
    "target_name = \"class\"\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.13, random_state=42)\n",
    "\n",
    "# We store both the data and target in a dataframe to ease plotting\n",
    "moons = pd.DataFrame(np.concatenate([X, y[:, np.newaxis]], axis=1),\n",
    "                     columns=feature_names + [target_name])\n",
    "moons[target_name] = moons[target_name].astype(\"category\")\n",
    "X, y = moons[feature_names], moons[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52021893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = moons.plot.scatter(\n",
    "    x=feature_names[0], y=feature_names[1], c=y,\n",
    "    s=50, cmap=plt.cm.RdBu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ca1d3-ceec-4588-b92b-3ab9dbbeee26",
   "metadata": {},
   "source": [
    "Looking at the dataset, we observe that a linear separation will not do a good enough job to discriminate both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa035c32-cd39-40f1-9553-517005db4b7d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Fit a <tt>LogisticRegression</tt> model on the dataset.</li>\n",
    "        <li>Using the helper class <tt>helper.plotting.DecisionBoundaryDisplay</tt>, draw the decision boundary of the model.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_35.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_36.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376929f1-84d8-4ec0-a642-c142be3f6ec9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Fit a <tt>LogisticRegression</tt> model on the dataset but this time insert a <tt>sklearn.preprocessing.PolynomialFeatures</tt> transformer.</li>\n",
    "        <li>Using the helper class <tt>helper.plotting.DecisionBoundaryDisplay</tt>, draw the decision boundary of the model.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_37.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a408b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_38.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a74811-8695-4846-8d2a-fbbfb77bb2a0",
   "metadata": {},
   "source": [
    "## What about SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e26464-0b11-4305-af4d-4298b057e469",
   "metadata": {},
   "source": [
    "Another family of linear algorithms are Support Vector Machine (SVM). The training paradigm is different from logistic regression. This model try to find the hyperplane that maximize the margin to the point close to the hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee45ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LinearSVC())\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26990ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = DecisionBoundaryDisplay.from_estimator(\n",
    "    model, X, cmap=plt.cm.RdBu,\n",
    ")\n",
    "_ = moons.plot.scatter(\n",
    "    x=feature_names[0], y=feature_names[1], c=y,\n",
    "    s=50, cmap=plt.cm.RdBu, ax=display.ax_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc6078-8e31-44f9-a861-7801b9d036d5",
   "metadata": {},
   "source": [
    "What made SVM interesting at some point was their capability to become non-linear using a so-called \"kernel trick\". The kernel trick allows to project the data in an higher dimensional space but without to build explicitely the kernel itself and only computing the dot product in this space. The class `SVC` allows to use such kernel. We will use a polynomial kernel to create something similar to the previous pipeline that used a `PolynomialFeatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1938701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel=\"poly\", degree=3))\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201cda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = DecisionBoundaryDisplay.from_estimator(\n",
    "    model, X, cmap=plt.cm.RdBu,\n",
    ")\n",
    "_ = moons.plot.scatter(\n",
    "    x=feature_names[0], y=feature_names[1], c=y,\n",
    "    s=50, cmap=plt.cm.RdBu, ax=display.ax_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080fd96f-4553-4752-812f-8872095802a4",
   "metadata": {},
   "source": [
    "One can even used different type of kernel, for instance Radial Basis Function (RBF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba96684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\"))\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = DecisionBoundaryDisplay.from_estimator(\n",
    "    model, X, cmap=plt.cm.RdBu,\n",
    ")\n",
    "_ = moons.plot.scatter(\n",
    "    x=feature_names[0], y=feature_names[1], c=y,\n",
    "    s=50, cmap=plt.cm.RdBu, ax=display.ax_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d79e7-5ac0-4b76-9fc1-6c297e795865",
   "metadata": {},
   "source": [
    "Be aware that SVM do not scale very well with the number of data point. Sometimes, it is better to use a kernel approximation and create the explicit kernel with a transformer such as `Nystroem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd663806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "model = make_pipeline(Nystroem(), LogisticRegression())\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0474f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = DecisionBoundaryDisplay.from_estimator(\n",
    "    model, X, cmap=plt.cm.RdBu,\n",
    ")\n",
    "_ = moons.plot.scatter(\n",
    "    x=feature_names[0], y=feature_names[1], c=y,\n",
    "    s=50, cmap=plt.cm.RdBu, ax=display.ax_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaafea-3121-4d22-8c90-0dbf117ad75b",
   "metadata": {},
   "source": [
    "We see that the decision boundary of this model is pretty similar to an SVM with an RBF kernel. Now, let's do an exercise to demonstrate the scaling limitation of the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/adult-census-numeric-all.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "X = data.drop(columns=target_name)\n",
    "y = data[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d2bc2-6c8a-4a3e-9953-37282b660440",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad3e0b-8c32-47d4-991f-95581c12669e",
   "metadata": {},
   "source": [
    "The dataset contains almost 50,000 samples that is already a lot for an SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fceac11-11db-4c26-81d9-231e7f200e40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Split the dataset into a training and testing sets.</li>\n",
    "        <li>Create a model containing a SVM that uses an RBF kernel. Check the time that the model needs to be fitted.</li>\n",
    "        <li>Repeat the same experiment with a model that uses a Nystroem kernel approsimation and a logistic regression.</li>\n",
    "        <li>Check the score of both models on the testing set.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5e61c-86d2-467e-9dc8-1a56bff6b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_39.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_40.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31365ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_41.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_42.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_43.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
