{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f353a938-5ce7-45a8-9e01-ef92a47c830f",
   "metadata": {},
   "source": [
    "# Hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc9efc3-61a8-490c-a142-a98f74f121b8",
   "metadata": {},
   "source": [
    "In past notebooks, we pointing out that some models' parameters had an impact on the statistical performance of the models. Usually, we would like to optimize these parameters such that the model trained is as good as possible. This optimization is called hyperparameters tuning.\n",
    "\n",
    "In this notebook, we will show a couple of method allowing to tune models' hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526728e2-ccb2-41e1-af33-0c055bf47874",
   "metadata": {},
   "source": [
    "## Introductory example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dca106-3397-425b-ae63-4ef3ea665cfe",
   "metadata": {},
   "source": [
    "We will take an example that we showed in the linear model where we discussed the impact of the $\\alpha$ parameter on a `Ridge` model. Indeed, we mentioned that this parameter allows to regularize more or less the model. However, there is no general rule specifying what is a good $\\alpha$ value. Indeed, it would depend of the dataset.\n",
    "\n",
    "Let's load a dataset to tackle a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c26f23-e66e-483f-a7a3-c4197964e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b94e94-f729-4d83-9e20-94f1eba8040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f213b42-7ec5-4202-937b-21be17dda280",
   "metadata": {},
   "source": [
    "Now, we will define a `Ridge` model where we will process the the data with add some interaction between features using a `PolynomialFeatures` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fa3f2-6653-43b3-b3cf-ba165e7e135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41bd73c-3308-4241-ab34-a64aa7e234da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(),\n",
    "    StandardScaler(),\n",
    "    Ridge(),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb5a05-cdcf-4fdb-aa93-c65364a82491",
   "metadata": {},
   "source": [
    "However, we did not change any of the default parameters given by scikit-learn. Let's evaluate this vanilla model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3d195-33bc-43e0-9743-fd089513207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, X, y)\n",
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d27f41-84d5-4c83-8fb7-a294552277c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e65bbb-47c9-4221-ae83-986b60525a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce666b9e-b85f-44fc-80b2-2ceb20e57b21",
   "metadata": {},
   "source": [
    "At this stage, there is nothing to tell use that our pipeline is the best pipeline that we could get. Indeed, we could imagine that the degree of the `PolynomialFeatures` could be higher or that the `Ridge` regressor should be more regularized. Let's check which parameters we could tune with the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc027b-ed16-416a-b75e-ca8aa8885bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.get_params():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacf736-8ea1-4735-a32b-40697ded7a59",
   "metadata": {},
   "source": [
    "Two important parameters of this model are `polynomialfeatures__degree` and `ridge__alpha`. We will try to find the optimal values of these parameters for the current dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945a302-ec4c-452e-976f-fe35f1803eb0",
   "metadata": {},
   "source": [
    "## Manual hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57597d0d-981b-4e77-9067-a8bb5c093a56",
   "metadata": {},
   "source": [
    "Before to show the automated tools allowing to make hyperparameters tuning in scikit-learn, we will manually make our own manual simplified version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5764ea-9cbc-40ce-bf96-6aaa5091e2e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "    <ul>\n",
    "        <li>Split the dataset into a training and testing set.</li>\n",
    "        <li>Make a nested <tt>for</tt> loop to try all the possible parameters combination that we defined in <tt>parameter_grid</tt>.</li>\n",
    "        <li>In the internal loop, use a cross-validation (using <tt>cross_val_score</tt>) on the training set to get a distribution of score.</li>\n",
    "        <li>Compute the mean and standard deviation of the cross-validation score and pick-up the best set of hyperparameters.</li>\n",
    "        <li>Retrain a model with the combination of the best hyperparameters and evalute it on the testing set.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c1fb2-ea56-4157-b953-b4dca41e0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a473ea4-1301-4526-9e77-7623a3e16970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab328fd-04dd-4c8c-8c07-8c4f99b2afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d421e-6f19-4e46-8f5d-cc8db77c509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_04.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfb449-6d7e-40fa-a7ec-208600ac086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_05.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7038eff-1314-45b9-b868-512a190c381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_06.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5907a6-d3fb-4f36-9839-891a3e339a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_07.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c99c28-3d95-499c-987c-ed12e7831ec1",
   "metadata": {},
   "source": [
    "## Hyperparameters search using a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21ee24-e089-480b-b289-313de45b2733",
   "metadata": {},
   "source": [
    "The search that we performed manually is indeed known as a grid-search: we try every possible combination of the parameter that we first provided. Scikit-learn provides a specific estimator that will make the processing that we did previously: during `fit`, it will perform a cross-validation and pick the optimal hyperparameters using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7722ca-c287-4940-9074-c7c7b34d049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_cv = GridSearchCV(model, param_grid=parameter_grid)\n",
    "search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5af3d-3a38-46c8-ae1a-bcc9bcaf8d65",
   "metadata": {},
   "source": [
    "We can get the best found parameters by looking at the fitted attributes `best_params_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b1a28-1dfc-4183-8db5-ec7ab1d0bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2bcc0-89c4-489c-8d4f-20dab7c664cb",
   "metadata": {},
   "source": [
    "We can even get more information regarding the different combinations of hyperparameters tried during `fit` by looking at the fitted attribute `cv_results_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9069f-875f-4c41-b290-ee49a84642b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258cd94-e49a-408a-8385-314aa778428f",
   "metadata": {},
   "source": [
    "In addition, at the end of the `fit` procedure, if the parameter `refit` is set to `True` (default), a model with the best combination will be trained (as we did in the manual hyperparameters search). We can check this model by looking at the fitted attribute `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170ae6a-f222-48ec-bc5f-72f3daece7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8789720-2639-44d3-a926-ad54246d4aa2",
   "metadata": {},
   "source": [
    "Indeed, this `best_estimator_` will be used when calling `predict` and `score` from the `GridSearchCV` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba44d8-2100-425c-94ff-c0f587c5c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f8f39-03a9-47ea-991d-ca933e1c4ccc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "    <br>\n",
    "    Since a <tt>GridSearchCV</tt> behave like any classifier or regressor, it can be used and evaluated by cross-validation. Use <tt>cross_validate</tt> to evaluate the previous grid-search model that we created.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37ff2f-3a50-4af6-8487-5e647fe6135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_08.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09989dc-9ebe-41f2-ab63-ac16b08a961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_09.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd63f7-25a4-418c-9005-5b4dbdc62d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f20250-4260-4f1d-be17-32005daca376",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION</b>:\n",
    "    <br>\n",
    "    Which limitation the grid-search approach suffer from?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0639f0-2ea1-441f-b618-88ec8ebd063f",
   "metadata": {},
   "source": [
    "## Randomized hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7bfa8-b02c-4a45-9324-b6794b045d4a",
   "metadata": {},
   "source": [
    "In the previous strategy, the grid-search has two limitations:\n",
    "\n",
    "- it only explores combination of parameters defined in the grid;\n",
    "- adding new parameters and values to explore will increase rapidly the cost of the search.\n",
    "\n",
    "`RandomizedSearchCV` allows to specify a distribution from which to draw parameter values. It allows to explore the hyperparamters space on a non-grid fashion and as a user, you can give a butget of the number of combination you want to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc627ac-e446-4df4-b7c9-05f3c82824b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "parameter_distributions = {\n",
    "    \"polynomialfeatures__degree\": np.arange(1, 5),\n",
    "    \"ridge__alpha\": loguniform(1, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24640ef0-ba45-4a5a-b493-da1945e74205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search_cv = RandomizedSearchCV(\n",
    "    model, param_distributions=parameter_distributions, n_iter=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b5e5b-4fc7-48b1-93d9-527a57fe6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(search_cv, X, y, return_estimator=True)\n",
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e269a7-36df-460c-96ad-2508d1f1cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62a6a4-90ff-43c1-a46a-4d7213dcf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in cv_results[\"estimator\"]:\n",
    "    print(est.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd6824-a67e-4097-9f2a-c7437d95e515",
   "metadata": {},
   "source": [
    "## Model with internal hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ce641-c798-403f-a3c5-4303f444d129",
   "metadata": {},
   "source": [
    "Some classifiers or regressors come with the some efficient hyperparameter selection, at least more efficient than a grid-search. Usually, the name of the classsifiers or regressors finish with `CV` (e.g. `RidgeCV`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a53a0e-211d-46ae-b7be-32d0dc5d9af6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>Create a pipeline made of a <tt>PolynomialFeatures</tt>, a <tt>StandardScaler</tt>, and a <tt>Ridge</tt>.</li>\n",
    "        <li>Create a grid-search by passing the previous pipeline and tune the parameter <tt>alpha</tt> such that you will try the values <tt>np.logspace(-2, 2, num=50)</tt>.</li>\n",
    "        <li>Fit the grid-search on the training set and check the time it takes.</li>\n",
    "        <li>Repeat the experiment by replacing the <tt>Ridge</tt> regressor by a <tt>RidgeCV</tt> regressor and removing the <tt>GridSearchCV</tt>.</li>\n",
    "    </ul>\n",
    "    Which approach is more efficient in terms of computational performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77fec3-0844-4e80-92e9-9036014ed817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_11.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3796e21-b172-4958-9151-06933bb6420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_12.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8927a4-513b-4a1b-82cd-a88f890375eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_13.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c48ee-e346-4bb2-a7bd-a8932eabd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_14.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66247e22-48cc-48bc-a5ee-e4be4ed51ae7",
   "metadata": {},
   "source": [
    "## Inspection of hyperparameters in cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b18131-94b4-4c40-81fd-6ce1e207d116",
   "metadata": {},
   "source": [
    "Sometimes, we perform a search cross-validation inside a cross-validation evaluation. In this case, we potentially have different set of hyperparameter values for each individual cross-validation split. We can indeed inspect these values. Let's define a `GridSearchCV` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68abe5-a849-4c12-bbd9-65419e45632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas = np.logspace(-2, 2, num=50)\n",
    "\n",
    "model = GridSearchCV(\n",
    "    make_pipeline(\n",
    "        PolynomialFeatures(),\n",
    "        StandardScaler(),\n",
    "        Ridge(),\n",
    "    ),\n",
    "    param_grid={\n",
    "        \"ridge__alpha\": alphas\n",
    "    },\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46915d7a-0826-4719-b5e3-ab821946d51c",
   "metadata": {},
   "source": [
    "Then, we can run a cross-validation by passing the model to `cross_validate`. In addition, we can store every model train on each cross-validation splits by setting `return_estimator` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c75fa-bb34-4a6b-af9b-8530396d6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X, y, cv=3, return_estimator=True)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38165e-dbc2-4e80-81f8-a3528140512a",
   "metadata": {},
   "source": [
    "We see that the `estimator` columns contain the different estimators. Thus we can check the `best_params_` stored by the `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ad7a1-ec9f-4a04-a207-fa9f69c3cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_cv_fold in cv_results[\"estimator\"]:\n",
    "    print(estimator_cv_fold.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1e45f-28ed-4813-a2b4-c8a90e096653",
   "metadata": {},
   "source": [
    "Such inspection allows to study the stability of the hyperparameter values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
